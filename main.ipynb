{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtC0oOa2_RXS"
      },
      "source": [
        "https://github.com/timschott/gpt-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkQc507B-0wK",
        "outputId": "906d4986-bcef-414c-cbc7-d8bad4eb00d3"
      },
      "source": [
        "!git clone https://github.com/timschott/gpt-2\n",
        "!mv gpt-2/* .\n",
        "!mv src/* .\n",
        "!python ./download_model.py 345M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 540, done.\u001b[K\n",
            "remote: Total 540 (delta 0), reused 0 (delta 0), pack-reused 540\u001b[K\n",
            "Receiving objects: 100% (540/540), 4.45 MiB | 22.32 MiB/s, done.\n",
            "Resolving deltas: 100% (318/318), done.\n",
            "Fetching checkpoint: 1.00kit [00:00, 817kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 56.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 826kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:18, 78.8Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 8.95Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 49.5Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 47.8Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfvZsYXU1lBs",
        "outputId": "7f5b06f0-3afb-4568-bd30-263533c41958"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "import model, sample, encoder\n",
        "\n",
        "def sample_model(\n",
        "    raw_text,\n",
        "    model_name='345M',\n",
        "    length=512,\n",
        "    batch_size=1,\n",
        "    temperature=0.9,\n",
        "    top_k=40,\n",
        "    top_p=0.9,\n",
        "):\n",
        "    \"\"\"\n",
        "    Run the sample_model\n",
        "    :model_name=117M : String, which model to use\n",
        "    :seed=None : Integer seed for random number generators, fix seed to\n",
        "     reproduce results\n",
        "    :nsamples=0 : Number of samples to return, if 0, continues to\n",
        "     generate samples indefinately.\n",
        "    :batch_size=1 : Number of batches (only affects speed/memory).\n",
        "    :length=None : Number of tokens in generated text, if None (default), is\n",
        "     determined by model hyperparameters\n",
        "    :temperature=1 : Float value controlling randomness in boltzmann\n",
        "     distribution. Lower temperature results in less random completions. As the\n",
        "     temperature approaches zero, the model will become deterministic and\n",
        "     repetitive. Higher temperature results in more random completions.\n",
        "    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n",
        "     considered for each step (token), resulting in deterministic completions,\n",
        "     while 40 means 40 words are considered at each step. 0 (default) is a\n",
        "     special setting meaning no restrictions. 40 generally is a good value.\n",
        "    :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling,\n",
        "     overriding top_k if set to a value > 0. A good setting is 0.9.\n",
        "    \"\"\"\n",
        "    enc = encoder.get_encoder(model_name)\n",
        "    hparams = model.default_hparams()\n",
        "    with open(os.path.join('models', model_name, 'hparams.json')) as f:\n",
        "        dict2 = json.load(f)\n",
        "        for key, value in hparams.items():\n",
        "            hparams[key] = dict2[key]\n",
        "\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "        output = sample.sample_sequence(\n",
        "            hparams=hparams, length=length,\n",
        "            context=context,\n",
        "            batch_size=batch_size,\n",
        "            temperature=temperature, top_k=top_k, top_p=top_p\n",
        "        )\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join('models', model_name))\n",
        "        saver.restore(sess, ckpt)\n",
        "\n",
        "        context_tokens = enc.encode(raw_text)\n",
        "        out = sess.run(output, feed_dict={\n",
        "          context: [context_tokens for _ in range(batch_size)]\n",
        "        })[:, len(context_tokens):]\n",
        "        return enc.decode(out[0])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    output = sample_model(\"Serena Williams is a very fantastic sports person Owning vast amounts of farina, marina, and argentina, She is currently 39 years old and is hugely macpherson Her fantasticness is admired by many, her mcphersonness as well Some say that Serena would sometimes go and get a adverse in, iversen, and congressperson Serena W. may have owned a w ou Her large collection of things includes a double u, a trouble you, a double-u, and a double you Williams was born in nineteen eighty-one Her birth was fantastic, not mentioning the everyone\")\n",
        "    print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " seemed to love the smell of the green #14 at the time At that time:'s daughter, Claire McMahon and the world was in transition\n",
            " In the early eighties, when he was eighteen, Serena became an elementary school teacher. On her 18th birthday, she attended the first of four weddings, the second of which was held in Indianapolis. At that time she had no idea what her place would be, but she soon learned, when in that marriage, she'd been sent to India, and the marriage ended up as a happy divorce. After divorcing her husband, she became interested in finance, especially in India, in general. \n",
            "In the nineties, she began to travel widely. When she went to the wedding of Shirley Jackson, her mind caught her eye. Shirley was the youngest daughter of the late Leonard Jackson and played football. I think we all know the story of Serena beating a girl on the football field, only to hear her mother tell her off. She traveled and became a household name. One of her biographies states that she was going to be the first black woman to win an Olympic gold medal, but things didn't go as planned. At this point, Serena didn't know how to relax, and she was struggling with cancer. The wedding was held in 1991, and was one of the most controversial of the day. Williams won it, as long as the guests were treated equally.\n",
            "The fashion wing of the establishment, that were the sponsors, wanted to avoid the event if possible. That was a huge deal, and because of the controversy, they couldn't fly their planes, and instead, they refused to let them. It was only after Serena won the gold medal that the ban came down. At that time, the reality was, it was extremely rare to win the gold medal in the host country, and Serena was one of them. While other players were showcasing their skills, Serena was busy being embarrassed in the celebrity dress. She was wearing enormous white tissue paper-covered socks, with a black watch. She was surrounded by white t shirts, and white vests. She went home, and at that moment, got so farmed out to her mother and brother by the colleen sportswear company. Serena grew up, because her mother didn't believe that she had a right to get involved in the business, and instead, encouraged her to be a student. \n",
            "One of her mother's favorite sports is the clay court, and while she\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}